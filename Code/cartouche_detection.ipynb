{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "cartouche_detection.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd8c8062"
      },
      "source": [
        "# Install requirements"
      ],
      "id": "cd8c8062"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec543117"
      },
      "source": [
        "pip install -r drive/MyDrive/requirements.txt"
      ],
      "id": "ec543117",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw6c4QSZv9zJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "uw6c4QSZv9zJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c1579c2"
      },
      "source": [
        "# Prepare dataset for training the model"
      ],
      "id": "8c1579c2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad31447b"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import fitz\n",
        "from PIL import Image\n",
        "from imageai.Detection.Custom import CustomObjectDetection\n",
        "\n",
        "\n",
        "def calc_percent(current, total, ndigits=2):\n",
        "    return round(current / max(total, 1) * 100, ndigits)\n",
        "\n",
        "\n",
        "def copy_label_images_data(src_dir='drive/MyDrive/pdf', dst_dir='drive/MyDrive/train_data/circle', train_data_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Copy the annotated pictures and marked files to the training data set folder\n",
        "    :param src_dir: Annotated picture folder\n",
        "    :param dst_dir: Training data folder\n",
        "    :param train_data_ratio: Proportion of training data, 80% of the total data is used as training data by default\n",
        "    \"\"\"\n",
        "    print('copy label images data: {} -> {}'.format(src_dir, dst_dir))\n",
        "\n",
        "    # List of all picture folders\n",
        "    pdf_dirs = []\n",
        "    for dir_name in os.listdir(src_dir):\n",
        "        if dir_name.startswith('.') or dir_name.endswith('.pdf'):\n",
        "            continue\n",
        "\n",
        "        dir_path = os.path.join(src_dir, dir_name)\n",
        "        pdf_dirs.append(dir_path)\n",
        "\n",
        "    # Training data set path\n",
        "    train_data_dir = os.path.join(dst_dir, 'train')\n",
        "    images_dir = os.path.join(train_data_dir, 'images')\n",
        "    annotations_dir = os.path.join(train_data_dir, 'annotations')\n",
        "\n",
        "    # Verify the data set path\n",
        "    validation_dir = os.path.join(dst_dir, 'validation')\n",
        "    images_valid_dir = os.path.join(validation_dir, 'images')\n",
        "    annotations_valid_dir = os.path.join(validation_dir, 'annotations')\n",
        "\n",
        "    # Find all the annotation data files\n",
        "    annotations_files = []\n",
        "    for pdf_dir in pdf_dirs:\n",
        "        filenames = os.listdir(pdf_dir)\n",
        "        filenames = list(filter(lambda name: name.endswith('.xml'), filenames))\n",
        "        for filename in filenames:\n",
        "            filename = filename.replace('.xml', '')\n",
        "            filepath = pdf_dir\n",
        "            annotations_files.append({\n",
        "                'filename': filename,\n",
        "                'path': filepath\n",
        "            })\n",
        "\n",
        "    # Calculate the number of training sets, and copy the data to the corresponding folders of the training set and the verification set\n",
        "    train_data_cnt = round(len(annotations_files) * train_data_ratio)\n",
        "    for item in annotations_files[:train_data_cnt]:\n",
        "        filename = item['filename']\n",
        "        filepath = item['path']\n",
        "\n",
        "        dst_filename = '{}_{}'.format(os.path.basename(item['path']), filename)\n",
        "\n",
        "        shutil.copyfile(\n",
        "            os.path.join(filepath, '{}.jpg'.format(filename)),\n",
        "            os.path.join(images_dir, '{}.jpg'.format(dst_filename))\n",
        "        )\n",
        "\n",
        "        shutil.copyfile(\n",
        "            os.path.join(filepath, '{}.xml'.format(filename)),\n",
        "            os.path.join(annotations_dir, '{}.xml'.format(dst_filename))\n",
        "        )\n",
        "\n",
        "    for item in annotations_files[train_data_cnt:]:\n",
        "        filename = item['filename']\n",
        "        filepath = item['path']\n",
        "\n",
        "        dst_filename = '{}_{}'.format(os.path.basename(item['path']), filename)\n",
        "\n",
        "        shutil.copyfile(\n",
        "            os.path.join(filepath, '{}.jpg'.format(filename)),\n",
        "            os.path.join(images_valid_dir, '{}.jpg'.format(dst_filename))\n",
        "        )\n",
        "\n",
        "        shutil.copyfile(\n",
        "            os.path.join(filepath, '{}.xml'.format(filename)),\n",
        "            os.path.join(annotations_valid_dir, '{}.xml'.format(dst_filename))\n",
        "        )\n",
        "\n",
        "\n",
        "def extract_images_from_pdf(pdf_dir):\n",
        "    \"\"\"\n",
        "    Extract the pictures in the PDF file and store them in a folder named after the PDF file\n",
        "    :param pdf_dir: The path of the folder where the PDF is stored\n",
        "    \"\"\"\n",
        "    print('extract all pdf to images(jpg): {}'.format(pdf_dir))\n",
        "\n",
        "    if not os.path.exists(pdf_dir):\n",
        "        print('pdf dir not exists: {}'.format(pdf_dir))\n",
        "        return\n",
        "\n",
        "    # Get a list of all PDF file names\n",
        "    pdf_names = os.listdir(pdf_dir)\n",
        "    pdf_names = list(filter(lambda name: name.endswith('.pdf'), pdf_names))\n",
        "\n",
        "    if not pdf_names:\n",
        "        print('pdf file not found')\n",
        "        return\n",
        "\n",
        "    cnt = 1\n",
        "    total = len(pdf_names)\n",
        "    percent = calc_percent(cnt, total)\n",
        "    print('{}% -> {}/{}'.format(percent, cnt, total))\n",
        "\n",
        "    # Extract one by one\n",
        "    for pdf_name in pdf_names:\n",
        "        # PDF file name\n",
        "        pdf_filename = os.path.join(pdf_dir, pdf_name)\n",
        "\n",
        "        # Image output folder name\n",
        "        img_output_dir = pdf_name.replace('.pdf', '')\n",
        "        img_output_dir = os.path.join(pdf_dir, img_output_dir)\n",
        "\n",
        "        # Delete the old picture output folder\n",
        "        if os.path.exists(img_output_dir):\n",
        "            shutil.rmtree(img_output_dir)\n",
        "\n",
        "        # Create a new image output folder\n",
        "        os.makedirs(img_output_dir)\n",
        "\n",
        "        # Open PDF files\n",
        "        with fitz.open(pdf_filename) as doc:\n",
        "            page_cnt = 0\n",
        "            page_total = doc.page_count\n",
        "\n",
        "            # Traverse all pages\n",
        "            for page in doc:\n",
        "                img_filename = os.path.join(img_output_dir, 'page-{}.jpg'.format(page.number))\n",
        "\n",
        "                # Get the bitmap of the page\n",
        "                pix = page.get_pixmap()\n",
        "\n",
        "                # Save the bitmap as a file\n",
        "                img = Image.frombytes('RGB', [pix.width, pix.height], pix.samples)\n",
        "                img.save(img_filename, 'PNG')\n",
        "\n",
        "                page_cnt += 1\n",
        "                page_percent = calc_percent(page_cnt, page_total)\n",
        "                print('\\rpdf: {}% -> {}/{}, page: {}% -> {}/{}'.format(percent, cnt, total, page_percent, page_cnt, page_total), end='')\n",
        "\n",
        "        # Print the progress\n",
        "        percent = calc_percent(cnt, total)\n",
        "        cnt += 1\n",
        "        print('{}% -> {}/{}'.format(percent, cnt, total))"
      ],
      "id": "ad31447b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0bd6e49"
      },
      "source": [
        "pdf_dir = 'drive/MyDrive/pdf'\n",
        "extract_images_from_pdf(pdf_dir)"
      ],
      "id": "d0bd6e49",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e40d6c62"
      },
      "source": [
        "# Copy the training data set"
      ],
      "id": "e40d6c62"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56a3efd5"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def copy_label_images_data(src_dir='drive/MyDrive/pdf', dst_dir='drive/MyDrive/train_data/circle', train_data_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Copy the annotated pictures and marked files to the training data set folder\n",
        "    :param src_dir: Annotated picture folder\n",
        "    :param dst_dir: Training data folder\n",
        "    :param train_data_ratio: Proportion of training data, 80% of the total data is used as training data by default\n",
        "    \"\"\"\n",
        "    print('copy label images data: {} -> {}'.format(src_dir, dst_dir))\n",
        "\n",
        "    # List of all picture folders\n",
        "    pdf_dirs = []\n",
        "    for dir_name in os.listdir(src_dir):\n",
        "        if dir_name.startswith('.') or dir_name.endswith('.pdf'):\n",
        "            continue\n",
        "\n",
        "        dir_path = os.path.join(src_dir, dir_name)\n",
        "        pdf_dirs.append(dir_path)\n",
        "\n",
        "    # Training data set path\n",
        "    train_data_dir = os.path.join(dst_dir, 'train')\n",
        "    images_dir = os.path.join(train_data_dir, 'images')\n",
        "    annotations_dir = os.path.join(train_data_dir, 'annotations')\n",
        "\n",
        "    # Verify the data set path\n",
        "    validation_dir = os.path.join(dst_dir, 'validation')\n",
        "    images_valid_dir = os.path.join(validation_dir, 'images')\n",
        "    annotations_valid_dir = os.path.join(validation_dir, 'annotations')\n",
        "\n",
        "    # Find all the annotation data files\n",
        "    annotations_files = []\n",
        "    for pdf_dir in pdf_dirs:\n",
        "        filenames = os.listdir(pdf_dir)\n",
        "        filenames = list(filter(lambda name: name.endswith('.xml'), filenames))\n",
        "        for filename in filenames:\n",
        "            filename = filename.replace('.xml', '')\n",
        "            filepath = pdf_dir\n",
        "            annotations_files.append({\n",
        "                'filename': filename,\n",
        "                'path': filepath\n",
        "            })\n",
        "\n",
        "    # Calculate the number of training sets, and copy the data to the corresponding folders of the training set and the verification set\n",
        "    train_data_cnt = round(len(annotations_files) * train_data_ratio)\n",
        "    for item in annotations_files[:train_data_cnt]:\n",
        "        filename = item['filename']\n",
        "        filepath = item['path']\n",
        "\n",
        "        dst_filename = '{}_{}'.format(os.path.basename(item['path']), filename)\n",
        "\n",
        "        shutil.copyfile(\n",
        "            os.path.join(filepath, '{}.jpg'.format(filename)),\n",
        "            os.path.join(images_dir, '{}.jpg'.format(dst_filename))\n",
        "        )\n",
        "\n",
        "        shutil.copyfile(\n",
        "            os.path.join(filepath, '{}.xml'.format(filename)),\n",
        "            os.path.join(annotations_dir, '{}.xml'.format(dst_filename))\n",
        "        )\n",
        "\n",
        "    for item in annotations_files[train_data_cnt:]:\n",
        "        filename = item['filename']\n",
        "        filepath = item['path']\n",
        "\n",
        "        dst_filename = '{}_{}'.format(os.path.basename(item['path']), filename)\n",
        "\n",
        "        shutil.copyfile(\n",
        "            os.path.join(filepath, '{}.jpg'.format(filename)),\n",
        "            os.path.join(images_valid_dir, '{}.jpg'.format(dst_filename))\n",
        "        )\n",
        "\n",
        "        shutil.copyfile(\n",
        "            os.path.join(filepath, '{}.xml'.format(filename)),\n",
        "            os.path.join(annotations_valid_dir, '{}.xml'.format(dst_filename))\n",
        "        )"
      ],
      "id": "56a3efd5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f71bc2f0"
      },
      "source": [
        "copy_label_images_data()"
      ],
      "id": "f71bc2f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76a6a6ee"
      },
      "source": [
        "# Annotate the data set"
      ],
      "id": "76a6a6ee"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13c21a90"
      },
      "source": [
        "# Correct the annotated data"
      ],
      "id": "13c21a90"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7da723e3"
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def correct_train_data():\n",
        "    xml_dirs = (\n",
        "        os.path.join('drive','MyDrive','train_data', 'circle', 'train', 'annotations'),\n",
        "        os.path.join('drive','MyDrive','train_data', 'circle', 'validation', 'annotations')\n",
        "    )\n",
        "\n",
        "    for xml_dir in xml_dirs:\n",
        "        xml_file_paths = os.listdir(xml_dir)\n",
        "        xml_file_paths = list(filter(lambda name: name.endswith('.xml'), xml_file_paths))\n",
        "\n",
        "        for xml_file_path in xml_file_paths:\n",
        "            print('correct train data: {}'.format(xml_file_path))\n",
        "            img_filename = xml_file_path.replace('.xml', '.jpg')\n",
        "            xml_file_path = os.path.join(xml_dir, xml_file_path)\n",
        "            with open(xml_file_path, 'r+') as fp:\n",
        "                xml_text = fp.read()\n",
        "                xml_text = re.sub('<filename>.*</filename>', '<filename>{}</filename>'.format(img_filename), xml_text)\n",
        "                fp.seek(0)\n",
        "                fp.write(xml_text)"
      ],
      "id": "7da723e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09c0c074"
      },
      "source": [
        "correct_train_data()"
      ],
      "id": "09c0c074",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b6e48bd"
      },
      "source": [
        "# Start training the model"
      ],
      "id": "4b6e48bd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93ea9db3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "\n",
        "def train():\n",
        "    trainer = DetectionModelTrainer()\n",
        "    trainer.setModelTypeAsYOLOv3()\n",
        "    trainer.setDataDirectory(data_directory=os.path.join('drive','MyDrive','train_data', 'circle'))\n",
        "    trainer.setTrainConfig(\n",
        "        object_names_array=['circle'],\n",
        "        batch_size=4,\n",
        "        num_experiments=200,\n",
        "        train_from_pretrained_model='pretrained-yolov3.h5'\n",
        "    )\n",
        "    trainer.trainModel()\n",
        "\n",
        "\n",
        "def init_tf():\n",
        "    # Set up GPU video memory to apply on demand to prevent insufficient video memory\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            # Currently, memory growth needs to be the same across GPUs\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "        except RuntimeError as e:\n",
        "            # Memory growth must be set before GPUs have been initialized\n",
        "            print(e)\n",
        "\n",
        "    print_is_gpu_available()\n",
        "\n",
        "\n",
        "def print_is_gpu_available():\n",
        "    print('gpu available: {}'.format(tf.test.is_gpu_available()))"
      ],
      "id": "93ea9db3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35adaaaf"
      },
      "source": [
        "init_tf()\n",
        "train()"
      ],
      "id": "35adaaaf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0bd49df"
      },
      "source": [
        "# After training, test the recognition effect"
      ],
      "id": "a0bd49df"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12181993"
      },
      "source": [
        "from imageai.Detection.Custom import CustomObjectDetection\n",
        "\n",
        "def test(img_path, img_out, minimum_percentage_probability=10):\n",
        "    \"\"\"\n",
        "    Recognition test\n",
        "    :param img_path \\\\Image file path\n",
        "    :param img_out \\\\Result image path\n",
        "    :param minimum_percentage_probability \\\\Minimum similarity of graphics\n",
        "    \"\"\"\n",
        "    print('test: {} -> {}'.format(img_path, img_out))\n",
        "\n",
        "        '''\n",
        "    /***************************************************************************************\n",
        "*    Title: ImageAI : Custom Object Detection\n",
        "*    Author: ImageAI Developers\n",
        "*    Date: 2019\n",
        "*    Code version: latest\n",
        "*    Availability: https://github.com/OlafenwaMoses/ImageAI/blob/master/imageai/Detection/Custom/CUSTOMDETECTION.md\n",
        "*\n",
        "***************************************************************************************/'''\n",
        "\n",
        "    # Load the model\n",
        "    detector = CustomObjectDetection()\n",
        "    detector.setModelTypeAsYOLOv3()\n",
        "    detector.setModelPath('drive/MyDrive/train_data/circle/models/detection_model-ex-138--loss-0014.575.h5')\n",
        "    detector.setJsonPath('drive/MyDrive/train_data/circle/models/detection_config.json')\n",
        "    detector.loadModel()\n",
        "\n",
        "    # Detect\n",
        "    detections = detector.detectObjectsFromImage(\n",
        "        input_image=img_path,\n",
        "        output_image_path=img_out,\n",
        "        minimum_percentage_probability=minimum_percentage_probability\n",
        "    )\n",
        "\n",
        "    # Print the result\n",
        "    for detection in detections:\n",
        "        print(\"{}: {} -> {}\".format(detection['name'], detection['percentage_probability'], detection['box_points']))"
      ],
      "id": "12181993",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b929d98"
      },
      "source": [
        "# Recognition effect test\n",
        "img_test = 'test.jpg'\n",
        "img_out = 'test_out.jpg'\n",
        "test(img_test, img_out)"
      ],
      "id": "6b929d98",
      "execution_count": null,
      "outputs": []
    }
  ]
}